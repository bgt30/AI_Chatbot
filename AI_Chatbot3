# 1. 사용환경 준비
import os
from getpass import getpass
import faiss
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_core.messages import HumanMessage
from langchain_core.prompts import ChatPromptTemplate
from langchain.document_loaders import PyPDFLoader
from langchain.text_splitter import CharacterTextSplitter, RecursiveCharacterTextSplitter
from langchain_community.vectorstores import FAISS
from langchain_core.runnables import RunnablePassthrough

# 1. API 키 설정
os.environ["OPENAI_API_KEY"] = getpass("OpenAI API key 입력: ")

# 2. 모델 로드
model = ChatOpenAI(model="gpt-4o-mini")

# 3. 문서 로드
loader = PyPDFLoader("~/desktop/Chatbot/인공지능산업최신동향_2024년11월호.pdf")
docs = loader.load()

# 4. 문서 청크로 나누기
# CharacterTextSplitter 사용
char_text_splitter = CharacterTextSplitter(
    separator="\n\n",
    chunk_size=100,
    chunk_overlap=10,
    length_function=len,
    is_separator_regex=False,
)
char_splits = char_text_splitter.split_documents(docs)

# RecursiveCharacterTextSplitter 사용
recursive_text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=100,
    chunk_overlap=10,
    length_function=len,
    is_separator_regex=False,
)
recursive_splits = recursive_text_splitter.split_documents(docs)

# 상위 10개 청크 출력
print("CharacterTextSplitter 청크:")
for i, chunk in enumerate(char_splits[:10]):
    print(f"청크 {i+1}: {chunk.page_content}\n")

print("RecursiveCharacterTextSplitter 청크:")
for i, chunk in enumerate(recursive_splits[:10]):
    print(f"청크 {i+1}: {chunk.page_content}\n")

# 5. 벡터 임베딩 생성
embeddings = OpenAIEmbeddings(model="text-embedding-ada-002")

# 6. 벡터 스토어 생성
vectorstore = FAISS.from_documents(documents=char_splits, embedding=embeddings)

# 7. FAISS를 Retriever로 변환
retriever = vectorstore.as_retriever(search_type="similarity", search_kwargs={"k": 1})

# 8. 프롬프트 템플릿 정의
contextual_prompt = ChatPromptTemplate.from_messages([
    ("system", "Answer the question using only the following context."),
    ("user", "Context: {context}\\n\\nQuestion: {question}")
])

# 9. RAG 체인 구성
class DebugPassThrough(RunnablePassthrough):
    def invoke(self, *args, **kwargs):
        output = super().invoke(*args, **kwargs)
        print("Debug Output:", output)
        return output

# 문서 리스트를 텍스트로 변환하는 클래스 정의
class ContextToText(RunnablePassthrough):
    def invoke(self, inputs, config=None, **kwargs):
        context_text = "\n".join([doc.page_content for doc in inputs["context"]])
        return {"context": context_text, "question": inputs["question"]}

# RAG 체인 구성
rag_chain_debug = {
    "context": retriever,
    "question": DebugPassThrough()
} | DebugPassThrough() | ContextToText() | contextual_prompt | model

# 10. 챗봇 구동 확인
while True:
    print("========================")
    query = input("질문을 입력하세요: ")
    response = rag_chain_debug.invoke({"context": retriever, "question": query})
    print("Final Response:")
    print(response.content)

# RAG는 는 사전에 학습되지 않은 정보에 대해 실시간 검색을 통해 더욱 정확하고 업데이트된 응답을 제공할 수 있도록 도와줍니다. 이는 챗봇이 사용자 질의에 대한 보다 구체적이고 사실에 기반한 응답을 제공하는 데 필수적인 기능입니다.**